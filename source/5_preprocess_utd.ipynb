{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertain temporal database : preprocess\n",
    "\n",
    "In here, we calculate the time column, delete some unused columns and change it into a prefered format, so we can use it for many scripts, especially for measuring time via 'main_pfpmeasure.ipynb'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = r\"../data/UTDATABASE/utd_20221222_0226/\"\n",
    "database_df = pd.read_csv(database_path + \"label.csv\")\n",
    "database_df.fillna(0, inplace=True)\n",
    "# database_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle time\n",
    "\n",
    "I assume hour can contribute to the traffic jam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_df['Datetime'] = pd.to_datetime(database_df['Datetime'], errors='coerce')\n",
    "first_datetime = database_df['Datetime'].min()\n",
    "database_df['Time'] = np.round((database_df['Datetime'] - first_datetime).dt.total_seconds() / 3600)\n",
    "database_df.sort_values(by=['Time'], ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: there is a time gap that is 120 hours in between, which I suspect is because of data loss. It make all the features have at least their period >= 120. Which I don't think is a good 'bug'. So I planned to delete that time gap. Even though it could lead to data loss, I hope the remaining data can still achieve good patterns. (There's still plenty of days to calculate.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "time_val_counts = database_df['Time'].value_counts()\n",
    "debug_time_df = database_df[ ['Time'] ] \n",
    "debug_time_df['Diff'] = debug_time_df.diff()\n",
    "delete_time_start, max_time_gap = debug_time_df['Time'][ debug_time_df['Diff'].idxmax() ], debug_time_df['Diff'][ debug_time_df['Diff'].idxmax() ]\n",
    "print(delete_time_start, max_time_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danger! delete time gap\n",
    "database_df = database_df[ database_df['Time'] >= delete_time_start ]\n",
    "database_df.drop(columns=['Datetime'], axis=1, inplace=True)\n",
    "database_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete unused columns\n",
    "\n",
    "We delete some columns to achieve faster running time, and hopefully, better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_columns = ['SensorCode', 'Datetime' ]\n",
    "database_df.drop([ col for col in database_df if col in deleted_columns ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete time related labels\n",
    "\n",
    "Because we think they won't really contribute much, but actually make the database sparser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_df.drop( [ col for col in database_df if ('HourTriple' in col) or ('WeekDay' in col) ], axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the preprocessed database\n",
    "\n",
    "The current format is that the 'Time' column is the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save into the same folder that contain input file\n",
    "database_df.to_csv(database_path + \"database.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb3de00e07e345391905e8474aaa8d141fe6b310547503c17a51563c220f85dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
